I"Ÿ<h1 id="research">Research</h1>

<p>The overarching goal of our research is to develop novel learning and 
control algorithms to enable robots to safely and efficiently collaborate 
with humans and other robots to accomplish complex tasks. The algorithms are 
applied to various robot platforms, including <a href="#wearable-robotics">wearable robotics</a>, <a href="#soft-robotics">soft robotics</a>, 
<a href="#unmanned-aerial-vehicles">unmanned aerial vehicles</a>, and <a href="#human-robot-collaboration">robot manipulators</a>. Please check the summary of each 
project below and feel free to contact us if you have any questions!</p>

<p>We greatly acknowledge the support from National Science Foundation, Office of Naval Research, 
Science Foundation Arizona, Arizona Department of Healthcare Services,</p>

<h2 id="wearable-robotics">Wearable Robotics</h2>
<p>The aging population and neurological disorders such as stroke 
and Parkinsonâ€™s disease lead to increased walking impairments. 
Traditional gait rehabilitation techniques involve multiple 
training sessions supervised by physical therapists. This paradigm 
is physically demanding for therapists, inconvenient for patients, 
and expensive for the entire healthcare system. Wearable assistive 
robots have been shown effective in restoring lost motor functions 
and improve training performance. We have developed intent estimation 
and adaptive control algorithms to personalize the robot assistance 
for different users in various tasks.</p>

<p>This project has been supported by the National Science Foundation and Science Foundation Arizona.</p>

<div class="col-sm-6 clearfix">
  <p><img src="http://localhost:4000/images/respic/Expstates.jpg" alt="" style="width: 465px; float: right; border: 10px" /></p>
</div>
<div class="col-sm-6 clearfix">
  <iframe width="450" height="253" src="https://www.youtube.com/embed/E2N7_usONDs" frameborder="0" allowfullscreen=""></iframe>
</div>
<p> Â  </p>

<h2 id="soft-robotics">Soft Robotics</h2>
<p>This rapidly growing research field of soft robotics combines robotics 
and materials engineering, to pre-program complex motions into flexible 
and compliant materials. These soft systems are engineered using low-cost
fabrication techniques, providing adaptable morphology in response to 
environmental changes, and are ideally suited for manipulating delicate objects 
and interfacing with the human body. We are particularly interested in developing 
soft robotic systems that assist or augment human capabilities. To this end, 
we are currently exploring two wearable soft robot systems: a soft supernumerary arm 
for power augmentation (left) and a soft exosuit for walking assistance (right). We collaborate
with the neurorehabiltiation center at the Barrow Neurological Institute to evaluate the soft robotic exosuit
for assistance and rehabilitation.</p>

<p>This project has been supported by the National Science Foundation, Arizona Department of Healthcare Services, and 
Global Sport Institute at ASU.</p>

<div class="col-sm-5 clearfix">
  <p><img src="http://localhost:4000/images/respic/soft_combined.png" alt="" style="width: 375px; float: right; border: 10px" /></p>
</div>
<div class="col-sm-7 clearfix">
  <iframe width="500" height="281" src="https://www.youtube.com/embed/zNls8IiVqg8" frameborder="0" allowfullscreen=""></iframe>
</div>
<p> Â  </p>

<h2 id="unmanned-aerial-vehicles">Unmanned Aerial Vehicles</h2>
<p>Unmanned aerial vehicles (UAVs) become popular in various applications, such as 
aerial photography, surveillance, search and rescue, and precision agriculture. However, 
autonomous operations of small UAVs in dynamic environments pose challenges on the design of vehicle hardware and 
the embedded autonomy algorithms. Our research in this area will 1) explore active morphing of the UAVs, 
2) develop accurate dynamic models and precision control algorithms, 3) integrate vision sensors 
for object detection and motion planning, and 4) enable multiple UAVs to cooperate in aerial surveillance, 
object transport, and aerial manipulation.</p>

<p>This project has been supported by the Salt River Project and the Northrop Grumman Corporation (through the Adaptive Intelligent Materials &amp; Systems Center (AIMS) at ASU).</p>

<div class="col-sm-5 clearfix">
  <p><img src="http://localhost:4000/images/respic/fuavweb.png" alt="" style="width: 375px; float: right; border: 10px" /></p>
</div>
<div class="col-sm-7 clearfix">
  <iframe width="500" height="281" src="https://www.youtube.com/embed/ETKrxgVHOgY" frameborder="0" allowfullscreen=""></iframe>
</div>
<p> Â  </p>

<h2 id="human-robot-collaboration">Human-Robot Collaboration</h2>
<p>Robots are increasingly employed in close proximity with humans. For the humans and robots to collaborate safely and 
efficiently, a robot needs to understand human intents, predict human actions, and optimize its own actions to 
complete a task with human. In this project, we will explore a game-theoretic framework to model the bilateral inference 
and decision making process between the human and robot. We are particularly interested in physical tasks that involve 
coupled dynamics between the human and robot. One major challenge is to model the human actions in highly dynamic tasks given 
the strong variability and uncertainty of humans. We will apply the developed algorithms in various human-robot collaboration 
scenarios, including autonomous vehicles, collaborative manufacturing, and wearable robots.</p>

<p>This project has been supported by the National Science Foundation. For more details about this project, please check <a href="http://localhost:4000/nri.html">this page</a>.</p>

<div class="col-sm-5 clearfix">
  <p><img src="http://localhost:4000/images/respic/phri2.jpg" alt="" style="width: 375px; float: right; border: 10px" /></p>
</div>
<div class="col-sm-7 clearfix">
  <iframe width="500" height="281" src="https://www.youtube.com/embed/luX1xlsm6UQ" frameborder="0" allowfullscreen=""></iframe>
</div>
<p> Â  </p>
:ET